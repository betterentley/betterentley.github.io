---
layout: post
title:  "Predicting Home Sale Prices"
subtitle: "Playing Around with Different Machine Learning Tools"
date:   2018-11-14 23:45:13 -0400
background: '/img/posts/house.jpg'
---

# Predicting Home Sale Prices

My friends at New York City Data Science Academy and I tried out a suite of machine learning tools on a dataset of home features and sale prices for several years in Ames, Iowa. It's a popular dataset that is available on [Kaggle](https://www.kaggle.com/c/house-prices-advanced-regression-techniques).

I've heard conflicting opinions on Kaggle competitions and I'm not sure where I stand. The "pro" case seems to be that doing a lot of Kaggle competitions will raise your profile as a data scientists, which can only be a good thing. The "con" case is that Kaggle competitions do not really reflect data science ability because some people are training against their own errors, so to speak, so the situation is not very applicable to most real-life data science scenarios. I'm told that the more cutting edge companies care less about Kaggle these days.

We just used the dataset as a playground for several Machine Learning tools. I specifically helped do Principal Component Analysis, K-nearest neighbors regression, LASSO regression, random forest, and assisted in combining the final, ensemble model.

We all wrote up a piece about it together for the NYC Data Science Academy blog. I don't want to just copy all the text here since it is not just my work, but you can check it out [here!](https://nycdatascience.com/blog/student-works/ames-iowa-housing-price-prediction-application-of-machine-learning-methods/)